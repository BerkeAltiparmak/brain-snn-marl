{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simulator for a discrete-time linear Spring-Mass-Damper (SMD) environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SpringMassDamperSimulator:\n",
    "    def __init__(self, mass, spring_const, damping_coeff, dt, noise_cov):\n",
    "        \"\"\"\n",
    "        Initialize the SMD simulator.\n",
    "        \n",
    "        Args:\n",
    "            mass (float): mass m.\n",
    "            spring_const (float): spring constant k.\n",
    "            damping_coeff (float): damping coefficient b.\n",
    "            dt (float): time-step size.\n",
    "            noise_cov (ndarray): Process noise covariance matrix, shape (2, 2).\n",
    "        \"\"\"\n",
    "        self.m = mass\n",
    "        self.k = spring_const\n",
    "        self.b = damping_coeff\n",
    "        self.dt = dt\n",
    "        self.noise_cov = noise_cov\n",
    "        # Define the observation matrix C.\n",
    "        # For example, we may assume we only observe position.\n",
    "        self.C = np.array([[1.0, 0.0]])  # shape (1, 2)\n",
    "\n",
    "    def step(self, state, control_input):\n",
    "        \"\"\"\n",
    "        Update the system state using Euler integration.\n",
    "        \n",
    "        Discrete-time dynamics:\n",
    "            x₁(t+1) = x₁(t) + dt * x₂(t)\n",
    "            x₂(t+1) = x₂(t) + dt * (1/m * (control_input - b*x₂(t) - k*x₁(t)))\n",
    "            \n",
    "        Also adds process noise v ~ N(0, noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): Current state [position; velocity], shape (2,).\n",
    "            control_input (float): Control input applied at time t.\n",
    "        \n",
    "        Returns:\n",
    "            next_state (ndarray): Updated state, shape (2,).\n",
    "            observation (ndarray): Noisy observation, shape matches self.C * state.\n",
    "        \"\"\"\n",
    "        pos, vel = state  # Unpack position and velocity\n",
    "        \n",
    "        # Compute derivatives using SMD dynamics.\n",
    "        dpos_dt = vel\n",
    "        dvel_dt = (control_input - self.b * vel - self.k * pos) / self.m\n",
    "        \n",
    "        # Euler integration to update state.\n",
    "        state_dot = np.array([dpos_dt, dvel_dt])\n",
    "        next_state = state + self.dt * state_dot\n",
    "        \n",
    "        # Add process noise v_t ~ N(0, noise_cov)\n",
    "        process_noise = np.random.multivariate_normal(mean=np.zeros(2), cov=self.noise_cov)\n",
    "        next_state = next_state + process_noise\n",
    "        \n",
    "        # Get noisy observation using the 'observe' method.\n",
    "        # We can set our own observation noise covariance in the observe method.\n",
    "        observation = self.observe(next_state)\n",
    "        \n",
    "        return next_state, observation\n",
    "\n",
    "    def observe(self, state, obs_noise_cov=np.array([[0.1]])):\n",
    "        \"\"\"\n",
    "        Generate a noisy observation of the current state.\n",
    "        \n",
    "        Observation equation:\n",
    "            y_t = C * x_t + w_t,\n",
    "        where w_t ~ N(0, obs_noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): State vector, shape (2,).\n",
    "            obs_noise_cov (ndarray): Observation noise covariance, shape (1, 1) \n",
    "                                     if observation is one-dimensional.\n",
    "        \n",
    "        Returns:\n",
    "            observation (ndarray): Noisy observation, shape (1,).\n",
    "        \"\"\"\n",
    "        # Linear observation: we assume we only observe the position.\n",
    "        observation = self.C @ state  # This is a (1,) vector.\n",
    "        \n",
    "        # Add observation noise.\n",
    "        w = np.random.multivariate_normal(mean=np.zeros(self.C.shape[0]), cov=obs_noise_cov)\n",
    "        observation = observation + w\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Coding Network implementation (LIF neurons, spike encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeCodingNetwork:\n",
    "    def __init__(self, lambda_decay, dims, threshold=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Spike Coding Network.\n",
    "        \n",
    "        Args:\n",
    "            lambda_decay (float): Voltage decay rate λ.\n",
    "            dims (int): Number of neurons (and dimension of state/input/spikes).\n",
    "            threshold (float): Voltage threshold for spiking.\n",
    "        \"\"\"\n",
    "        self.lambda_decay = lambda_decay\n",
    "        self.dims = dims\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # We initialize the slow and fast recurrent weight matrices.\n",
    "        # In SCNs, fast recurrent connections are typically set as Ω_f = -D^T D.\n",
    "        # But here I initialize them to zero and hopefully later they can be set/learned?\n",
    "        # I should check this later...\n",
    "        self.Omega_s = np.zeros((dims, dims))   # slow recurrent weights\n",
    "        self.Omega_f = np.zeros((dims, dims))   # fast recurrent weights\n",
    "        \n",
    "        # Decoding matrix D maps between spike space and continuous space.\n",
    "        # For simplicity, we assume D is square and initialize it randomly.\n",
    "        self.D = np.random.randn(dims, dims)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Spike encoding of a continuous variable x.\n",
    "        \n",
    "        For simplicity, we assume a linear encoding:\n",
    "            potentials = D^T x\n",
    "        and then threshold the potentials to generate binary spikes.\n",
    "        \n",
    "        Args:\n",
    "            x (ndarray): Continuous input vector, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Encoded binary spike vector, shape (dims,).\n",
    "        \"\"\"\n",
    "        potentials = self.D.T @ x\n",
    "        spikes = (potentials >= self.threshold).astype(float)\n",
    "        return spikes\n",
    "\n",
    "    def update_voltages(self, voltages, inputs, r, s, noise_std=0.01):\n",
    "        \"\"\"\n",
    "        Update the membrane voltages using the following dynamics:\n",
    "        \n",
    "            v_dot = -λ v + Ω_s r + Ω_f s + Input + noise\n",
    "            \n",
    "        and then perform Euler integration:\n",
    "        \n",
    "            v_{t+1} = v_t + v_dot   (assuming dt=1)\n",
    "        \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (dims,).\n",
    "            inputs (ndarray): External input currents, shape (dims,).\n",
    "            r (ndarray): Filtered spike trains (e.g., low-pass filtered spikes), shape (dims,).\n",
    "            s (ndarray): Recent spikes, shape (dims,).\n",
    "            noise_std (float): Standard deviation for Gaussian noise.\n",
    "            \n",
    "        Returns:\n",
    "            new_voltages (ndarray): Updated membrane voltages, shape (dims,).\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(0, noise_std, size=voltages.shape)\n",
    "        # Compute the derivative of the voltages.\n",
    "        v_dot = (-self.lambda_decay * voltages +\n",
    "                 self.Omega_s @ r +\n",
    "                 self.Omega_f @ s +\n",
    "                 inputs +\n",
    "                 noise)\n",
    "        # Euler integration with dt=1.\n",
    "        new_voltages = voltages + v_dot\n",
    "        return new_voltages\n",
    "\n",
    "    def generate_spikes(self, voltages):\n",
    "        \"\"\"\n",
    "        Generate spikes based on the current membrane voltages.\n",
    "        \n",
    "        If a neuron's voltage exceeds the threshold, it emits a spike and the voltage is reset.\n",
    "        \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Binary vector indicating spikes, shape (dims,).\n",
    "            updated_voltages (ndarray): Voltages after spike reset, shape (dims,).\n",
    "        \"\"\"\n",
    "        spikes = (voltages >= self.threshold).astype(float)\n",
    "        # Reset the voltages for neurons that have spiked.\n",
    "        updated_voltages = np.copy(voltages)\n",
    "        updated_voltages[spikes == 1] = 0.0\n",
    "        return spikes, updated_voltages\n",
    "\n",
    "    def decode(self, spikes):\n",
    "        \"\"\"\n",
    "        Decode spikes to recover the continuous variable estimate.\n",
    "        \n",
    "        Here we assume a linear decoding:\n",
    "            x_hat = D @ spikes\n",
    "        In a full implementation, one might low-pass filter the spikes (r) and then decode.\n",
    "        \n",
    "        Args:\n",
    "            spikes (ndarray): Binary spike vector, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat (ndarray): Decoded continuous estimate, shape (dims,).\n",
    "        \"\"\"\n",
    "        x_hat = self.D @ spikes\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter module to perform optimal estimation (with delayed feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterSCN:\n",
    "    def __init__(self, A_init, B_init, C_init, L_init, delay):\n",
    "        \"\"\"\n",
    "        Initialize the Kalman filter with delay.\n",
    "        \n",
    "        Args:\n",
    "            A_init (ndarray): Initial system matrix A, shape (n, n).\n",
    "            B_init (ndarray): Initial control matrix B, shape (n, p).\n",
    "            C_init (ndarray): Initial observation matrix C, shape (m, n).\n",
    "            L_init (ndarray): Initial Kalman gain matrix L, shape (n, m).\n",
    "            delay (int): Sensory feedback delay τ (in timesteps).\n",
    "        \"\"\"\n",
    "        self.A = A_init\n",
    "        self.B = B_init\n",
    "        self.C = C_init\n",
    "        self.L = L_init\n",
    "        self.delay = delay\n",
    "        \n",
    "        # Should we maintain a buffer for state estimates to handle delays?\n",
    "        # For simplicity, I'll assume the caller provides the delayed state estimate.\n",
    "    \n",
    "    def predict_state(self, x_hat, u):\n",
    "        \"\"\"\n",
    "        Kalman prediction step.\n",
    "        \n",
    "        Predict the next state estimate based on the current estimate and control:\n",
    "            x_hat_pred = A x_hat + B u\n",
    "        \n",
    "        Args:\n",
    "            x_hat (ndarray): Current state estimate, shape (n,).\n",
    "            u (ndarray): Control input at time t, shape (p,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_pred (ndarray): Predicted next state, shape (n,).\n",
    "        \"\"\"\n",
    "        x_hat_pred = self.A @ x_hat + self.B @ u\n",
    "        return x_hat_pred\n",
    "\n",
    "    def update_state(self, x_hat_pred, y_delayed, x_hat_delayed):\n",
    "        \"\"\"\n",
    "        Kalman update step, incorporating delayed observation.\n",
    "        \n",
    "        This function implements:\n",
    "            x_hat_updated = x_hat_pred + L (y_{t+1-delay} - C x_hat_delayed)\n",
    "        \n",
    "        Args:\n",
    "            x_hat_pred (ndarray): Predicted state estimate at time t+1, shape (n,).\n",
    "            y_delayed (ndarray): Observation at time (t+1 - delay), shape (m,).\n",
    "            x_hat_delayed (ndarray): State estimate at time (t+1 - delay), shape (n,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_updated (ndarray): Updated state estimate, shape (n,).\n",
    "        \"\"\"\n",
    "        innovation = y_delayed - self.C @ x_hat_delayed  # prediction error (innovation)\n",
    "        x_hat_updated = x_hat_pred + self.L @ innovation\n",
    "        return x_hat_updated\n",
    "\n",
    "    def adapt_kalman_gain(self, error_current, error_delayed, learning_rate):\n",
    "        \"\"\"\n",
    "        Adapt the Kalman gain L using a local plasticity rule.\n",
    "        \n",
    "        Based on the Bio-OFC rule:\n",
    "            ΔL ∝ L (error_current) (error_delayed)^T\n",
    "        \n",
    "        where error_current = y_t - C x_hat_t and error_delayed = y_{t-delay} - C x_hat_{t-delay}.\n",
    "        \n",
    "        Args:\n",
    "            error_current (ndarray): Current prediction error, shape (m,).\n",
    "            error_delayed (ndarray): Delayed prediction error, shape (m,).\n",
    "            learning_rate (float): Step size for the adaptation.\n",
    "            \n",
    "        Updates self.L in place.\n",
    "        \"\"\"\n",
    "        # Outer product of errors (we assume L multiplies from left).\n",
    "        # TODO: Dimensional check before multiplication?\n",
    "        delta_L = learning_rate * self.L * np.outer(error_current, error_delayed)\n",
    "        self.L += delta_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal control using a policy-gradient-based learning rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientControllerSCN:\n",
    "    def __init__(self, K_init, noise_std, learning_rate, momentum=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the policy gradient based controller.\n",
    "        \n",
    "        Args:\n",
    "            K_init (ndarray): Initial control gain matrix K with shape (p, n),\n",
    "                              where p = control dimension, n = state dimension.\n",
    "            noise_std (float): Standard deviation of the exploration noise.\n",
    "            learning_rate (float): Learning rate for policy gradient updates.\n",
    "            momentum (float): Momentum parameter (default is 0), for smoothing updates.\n",
    "        \"\"\"\n",
    "        self.K = K_init.copy()\n",
    "        self.noise_std = noise_std\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        # Initialize the momentum accumulator for gradients with zeros\n",
    "        self.G = np.zeros_like(K_init)\n",
    "\n",
    "    def compute_action(self, state_estimate):\n",
    "        \"\"\"\n",
    "        Compute the control action with exploration noise.\n",
    "        \n",
    "        The deterministic part is given by the linear control law:\n",
    "            u_det = -K x_hat_t\n",
    "        and then we add Gaussian noise to encourage exploration:\n",
    "            u_t = u_det + noise, where noise ∼ N(0, noise_std)\n",
    "            \n",
    "        Args:\n",
    "            state_estimate (ndarray): Current state estimate x̂_t with shape (n,).\n",
    "            \n",
    "        Returns:\n",
    "            u (ndarray): Control action, shape (p,).\n",
    "            noise (ndarray): The exploration noise added to the control, shape (p,).\n",
    "        \"\"\"\n",
    "        # Compute deterministic control action.\n",
    "        u_det = -self.K @ state_estimate\n",
    "        # Generate exploration noise.\n",
    "        noise = np.random.normal(0, self.noise_std, size=u_det.shape)\n",
    "        # Compute final control action.\n",
    "        u = u_det + noise\n",
    "        return u, noise\n",
    "\n",
    "    def compute_eligibility_trace(self, prev_trace, state_estimate, noise):\n",
    "        \"\"\"\n",
    "        Compute the eligibility trace update based on the policy gradient formulation.\n",
    "        \n",
    "        The eligibility trace is accumulated as:\n",
    "            Z_t = Z_{t-1} + noise * (state_estimate)^T\n",
    "            \n",
    "        Args:\n",
    "            prev_trace (ndarray): Previous eligibility trace Z_{t-1} with shape (p, n).\n",
    "            state_estimate (ndarray): Current state estimate x̂_t with shape (n,).\n",
    "            noise (ndarray): The exploration noise added to control, shape (p,).\n",
    "            \n",
    "        Returns:\n",
    "            trace (ndarray): Updated eligibility trace Z_t with shape (p, n).\n",
    "        \"\"\"\n",
    "        # The outer product noise (p,) and state_estimate (n,) gives a (p, n) matrix.\n",
    "        delta_trace = np.outer(noise, state_estimate)\n",
    "        trace = prev_trace + delta_trace\n",
    "        return trace\n",
    "\n",
    "    def update_policy(self, eligibility_trace, cost):\n",
    "        \"\"\"\n",
    "        Update the control gain matrix K using a policy gradient update.\n",
    "        \n",
    "        The update rule is:\n",
    "            ∆K ∝ -cost * eligibility_trace\n",
    "        With momentum incorporated, we update as:\n",
    "            G_t = momentum * G_{t-1} + cost * eligibility_trace\n",
    "            K_new = K_old - learning_rate * G_t\n",
    "        \n",
    "        Args:\n",
    "            eligibility_trace (ndarray): Current eligibility trace Z_t with shape (p, n).\n",
    "            cost (float): The cost incurred at the current time step.\n",
    "            \n",
    "        This method updates self.K in place.\n",
    "        \"\"\"\n",
    "        # Incorporate momentum in the gradient update.\n",
    "        self.G = self.momentum * self.G + cost * eligibility_trace\n",
    "        # Update the control gain matrix K in the negative gradient direction.\n",
    "        self.K = self.K - self.learning_rate * self.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Bio-OFC module combining Kalman filtering and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioOFC:\n",
    "    def __init__(self, kalman_filter, controller, system_matrices):\n",
    "        \"\"\"\n",
    "        Initialize the Bio-OFC module.\n",
    "        \n",
    "        Args:\n",
    "            kalman_filter (KalmanFilterSCN): An instance of KalmanFilterSCN.\n",
    "            controller (PolicyGradientControllerSCN): An instance of PolicyGradientControllerSCN.\n",
    "            system_matrices (dict): Dictionary containing system matrices:\n",
    "                - 'A': System matrix A.\n",
    "                - 'B': Input matrix B.\n",
    "                - 'C': Observation matrix C.\n",
    "        \"\"\"\n",
    "        self.kf = kalman_filter\n",
    "        self.controller = controller\n",
    "        self.A = system_matrices['A']\n",
    "        self.B = system_matrices['B']\n",
    "        self.C = system_matrices['C']\n",
    "    \n",
    "    def step(self, x_hat, u, observation, delayed_observation, x_hat_delayed, params):\n",
    "        \"\"\"\n",
    "        Performs a single step of optimal feedback control.\n",
    "        \n",
    "        The step consists of:\n",
    "         1. Predict: x_hat_pred = A x_hat + B u.\n",
    "         2. Update: x_hat_updated = x_hat_pred + L (y_delayed - C x_hat_delayed).\n",
    "         3. Compute control action: u_new = -K x_hat_updated + exploration_noise.\n",
    "         4. (Optionally) Update the internal weights using the error signals.\n",
    "         \n",
    "        Args:\n",
    "            x_hat (ndarray): Current state estimate, shape (n,).\n",
    "            u (ndarray): Current control input, shape (p,).\n",
    "            observation (ndarray): Current (possibly delayed) observation y_t.\n",
    "            delayed_observation (ndarray): Observation from time t+1-τ.\n",
    "            x_hat_delayed (ndarray): State estimate from time t+1-τ.\n",
    "            params (dict): Additional parameters, which may include:\n",
    "                - 'learning_rate_kf': learning rate for Kalman gain update.\n",
    "                - 'learning_rate_controller': learning rate for controller update.\n",
    "                - 'cost': current cost incurred.\n",
    "                - 'prev_eligibility': previous eligibility trace for the controller.\n",
    "                - 'error_delayed': error from delayed measurement (if computed externally).\n",
    "                \n",
    "        Returns:\n",
    "            x_hat_updated (ndarray): Updated state estimate.\n",
    "            u_new (ndarray): New control action.\n",
    "            new_eligibility (ndarray): Updated controller eligibility trace.\n",
    "        \"\"\"\n",
    "        # 1. Prediction step using Kalman filter:\n",
    "        x_hat_pred = self.kf.predict_state(x_hat, u)\n",
    "        \n",
    "        # 2. Update state estimate with delayed observation:\n",
    "        x_hat_updated = self.kf.update_state(x_hat_pred, delayed_observation, x_hat_delayed)\n",
    "        \n",
    "        # (Optional) Compute innovation error for possible learning of Kalman gain:\n",
    "        error = delayed_observation - self.C @ x_hat_delayed\n",
    "        \n",
    "        # For updating Kalman gain L (if using a delayed error term)\n",
    "        if 'error_delayed' in params:\n",
    "            self.kf.adapt_kalman_gain(error, params['error_delayed'], params.get('learning_rate_kf', 0.001))\n",
    "        \n",
    "        # 3. Use the updated state estimate to compute control action.\n",
    "        u_new, noise = self.controller.compute_action(x_hat_updated)\n",
    "        \n",
    "        # 4. Update controller eligibility trace.\n",
    "        prev_trace = params.get('prev_eligibility', np.zeros_like(self.controller.K))\n",
    "        new_trace = self.controller.compute_eligibility_trace(prev_trace, x_hat_updated, noise)\n",
    "        \n",
    "        # 5. Update the controller (policy) using the current cost signal.\n",
    "        cost = params.get('cost', 0.0)\n",
    "        self.controller.update_policy(new_trace, cost)\n",
    "        \n",
    "        return x_hat_updated, u_new, new_trace\n",
    "\n",
    "    def adapt_system_matrices(self, error, x_hat_delayed, u_delayed, x_hat_next_delayed, learning_rates):\n",
    "        \"\"\"\n",
    "        Adapt the system matrices A, B, and C using local plasticity rules.\n",
    "        \n",
    "        The rules are:\n",
    "            ΔA ∝ L * error * (x_hat_delayed)^T\n",
    "            ΔB ∝ L * error * (u_delayed)^T\n",
    "            ΔC ∝ error * (x_hat_next_delayed)^T\n",
    "        \n",
    "        Args:\n",
    "            error (ndarray): Prediction error at time t, computed as y_t - C x_hat_t.\n",
    "            x_hat_delayed (ndarray): Delayed state estimate x_hat_{t-τ}, shape (n,).\n",
    "            u_delayed (ndarray): Delayed control input u_{t-τ}, shape (p,).\n",
    "            x_hat_next_delayed (ndarray): Delayed state estimate at time t+1, shape (n,).\n",
    "            learning_rates (dict): Dictionary of learning rates with keys:\n",
    "                - 'A': learning rate for A.\n",
    "                - 'B': learning rate for B.\n",
    "                - 'C': learning rate for C.\n",
    "        \"\"\"\n",
    "        lr_A = learning_rates.get('A', 0.001)\n",
    "        lr_B = learning_rates.get('B', 0.001)\n",
    "        lr_C = learning_rates.get('C', 0.001)\n",
    "        \n",
    "        # Adapt A: ΔA ∝ L * error * (x_hat_delayed)^T\n",
    "        delta_A = lr_A * self.kf.L @ np.outer(error, x_hat_delayed)\n",
    "        self.A += delta_A\n",
    "        self.kf.A = self.A  # update the Kalman filter's internal A\n",
    "        \n",
    "        # Adapt B: ΔB ∝ L * error * (u_delayed)^T\n",
    "        delta_B = lr_B * self.kf.L @ np.outer(error, u_delayed)\n",
    "        self.B += delta_B\n",
    "        self.kf.B = self.B  # update the Kalman filter's internal B\n",
    "        \n",
    "        # Adapt C: ΔC ∝ error * (x_hat_next_delayed)^T\n",
    "        delta_C = lr_C * np.outer(error, x_hat_next_delayed)\n",
    "        self.C += delta_C\n",
    "        self.kf.C = self.C  # update the Kalman filter's internal C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

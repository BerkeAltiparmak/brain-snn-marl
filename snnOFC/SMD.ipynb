{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simulator for a discrete-time linear Spring-Mass-Damper (SMD) environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SpringMassDamperSimulator:\n",
    "    def __init__(self, mass, spring_const, damping_coeff, dt, noise_cov):\n",
    "        \"\"\"\n",
    "        Initialize the SMD simulator.\n",
    "        \n",
    "        Args:\n",
    "            mass (float): mass m.\n",
    "            spring_const (float): spring constant k.\n",
    "            damping_coeff (float): damping coefficient b.\n",
    "            dt (float): time-step size.\n",
    "            noise_cov (ndarray): Process noise covariance matrix, shape (2, 2).\n",
    "        \"\"\"\n",
    "        self.m = mass\n",
    "        self.k = spring_const\n",
    "        self.b = damping_coeff\n",
    "        self.dt = dt\n",
    "        self.noise_cov = noise_cov\n",
    "        # Define the observation matrix C.\n",
    "        # For example, we may assume we only observe position.\n",
    "        self.C = np.array([[1.0, 0.0]])  # shape (1, 2)\n",
    "\n",
    "    def step(self, state, control_input):\n",
    "        \"\"\"\n",
    "        Update the system state using Euler integration.\n",
    "        \n",
    "        Discrete-time dynamics:\n",
    "            x₁(t+1) = x₁(t) + dt * x₂(t)\n",
    "            x₂(t+1) = x₂(t) + dt * (1/m * (control_input - b*x₂(t) - k*x₁(t)))\n",
    "            \n",
    "        Also adds process noise v ~ N(0, noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): Current state [position; velocity], shape (2,).\n",
    "            control_input (float): Control input applied at time t.\n",
    "        \n",
    "        Returns:\n",
    "            next_state (ndarray): Updated state, shape (2,).\n",
    "            observation (ndarray): Noisy observation, shape matches self.C * state.\n",
    "        \"\"\"\n",
    "        pos, vel = state  # Unpack position and velocity\n",
    "        \n",
    "        # Compute derivatives using SMD dynamics.\n",
    "        dpos_dt = vel\n",
    "        dvel_dt = (control_input - self.b * vel - self.k * pos) / self.m\n",
    "        \n",
    "        # Euler integration to update state.\n",
    "        state_dot = np.array([dpos_dt, dvel_dt])\n",
    "        next_state = state + self.dt * state_dot\n",
    "        \n",
    "        # Add process noise v_t ~ N(0, noise_cov)\n",
    "        process_noise = np.random.multivariate_normal(mean=np.zeros(2), cov=self.noise_cov)\n",
    "        next_state = next_state + process_noise\n",
    "        \n",
    "        # Get noisy observation using the 'observe' method.\n",
    "        # We can set our own observation noise covariance in the observe method.\n",
    "        observation = self.observe(next_state)\n",
    "        \n",
    "        return next_state, observation\n",
    "\n",
    "    def observe(self, state, obs_noise_cov=np.array([[0.1]])):\n",
    "        \"\"\"\n",
    "        Generate a noisy observation of the current state.\n",
    "        \n",
    "        Observation equation:\n",
    "            y_t = C * x_t + w_t,\n",
    "        where w_t ~ N(0, obs_noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): State vector, shape (2,).\n",
    "            obs_noise_cov (ndarray): Observation noise covariance, shape (1, 1) \n",
    "                                     if observation is one-dimensional.\n",
    "        \n",
    "        Returns:\n",
    "            observation (ndarray): Noisy observation, shape (1,).\n",
    "        \"\"\"\n",
    "        # Linear observation: we assume we only observe the position.\n",
    "        observation = self.C @ state  # This is a (1,) vector.\n",
    "        \n",
    "        # Add observation noise.\n",
    "        w = np.random.multivariate_normal(mean=np.zeros(self.C.shape[0]), cov=obs_noise_cov)\n",
    "        observation = observation + w\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Coding Network implementation (LIF neurons, spike encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SpikeCodingNetwork:\n",
    "    def __init__(self, lambda_decay, n_neurons, state_dim, threshold=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Spike Coding Network.\n",
    "        \n",
    "        Args:\n",
    "            lambda_decay (float): Voltage decay rate λ.\n",
    "            n_neurons (int): Number of spiking neurons.\n",
    "            state_dim (int): Dimension of the continuous state.\n",
    "            threshold (float): Voltage threshold for spiking.\n",
    "        \"\"\"\n",
    "        self.lambda_decay = lambda_decay\n",
    "        self.n_neurons = n_neurons\n",
    "        self.state_dim = state_dim\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Initialize the slow and fast recurrent weight matrices.\n",
    "        self.Omega_s = np.zeros((n_neurons, n_neurons))   # slow recurrent weights\n",
    "        self.Omega_f = np.zeros((n_neurons, n_neurons))   # fast recurrent weights\n",
    "        \n",
    "        # Encoding/decoding matrix: map state_dim to n_neurons.\n",
    "        # For encoding, D has shape (n_neurons, state_dim).\n",
    "        self.D = np.random.randn(n_neurons, state_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Spike encoding of a continuous variable x.\n",
    "        \n",
    "        For simplicity, we assume a linear encoding:\n",
    "            potentials = D @ x\n",
    "        and then threshold the potentials to generate binary spikes.\n",
    "        \n",
    "        Args:\n",
    "            x (ndarray): Continuous input vector, shape (state_dim,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Encoded binary spike vector, shape (n_neurons,).\n",
    "        \"\"\"\n",
    "        potentials = self.D @ x  # Shape: (n_neurons,)\n",
    "        spikes = (potentials >= self.threshold).astype(float)\n",
    "        return spikes\n",
    "\n",
    "    def update_voltages(self, voltages, inputs, r, s, noise_std=0.01):\n",
    "        \"\"\"\n",
    "        Update the membrane voltages using:\n",
    "        \n",
    "            v_dot = -λ v + Ω_s r + Ω_f s + Input + noise\n",
    "            \n",
    "        and then update:\n",
    "        \n",
    "            v_{t+1} = v_t + v_dot   (assuming dt=1)\n",
    "            \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (n_neurons,).\n",
    "            inputs (ndarray): External input currents, shape (n_neurons,).\n",
    "            r (ndarray): Filtered spike trains, shape (n_neurons,).\n",
    "            s (ndarray): Recent spikes, shape (n_neurons,).\n",
    "            noise_std (float): Standard deviation for Gaussian noise.\n",
    "            \n",
    "        Returns:\n",
    "            new_voltages (ndarray): Updated membrane voltages, shape (n_neurons,).\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(0, noise_std, size=voltages.shape)\n",
    "        v_dot = (-self.lambda_decay * voltages +\n",
    "                 self.Omega_s @ r +\n",
    "                 self.Omega_f @ s +\n",
    "                 inputs +\n",
    "                 noise)\n",
    "        new_voltages = voltages + v_dot\n",
    "        return new_voltages\n",
    "\n",
    "    def generate_spikes(self, voltages):\n",
    "        \"\"\"\n",
    "        Generate spikes based on the current membrane voltages. Neurons that exceed the \n",
    "        threshold emit a spike and their voltage is reset.\n",
    "        \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (n_neurons,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Binary spike vector, shape (n_neurons,).\n",
    "            updated_voltages (ndarray): Voltages after spike reset, shape (n_neurons,).\n",
    "        \"\"\"\n",
    "        spikes = (voltages >= self.threshold).astype(float)\n",
    "        updated_voltages = np.copy(voltages)\n",
    "        updated_voltages[spikes == 1] = 0.0\n",
    "        return spikes, updated_voltages\n",
    "\n",
    "    def decode(self, spikes):\n",
    "        \"\"\"\n",
    "        Decode spikes back into a continuous estimate.\n",
    "        \n",
    "        A simple decoding rule is to use the pseudoinverse of D:\n",
    "            x_hat = D^+ @ spikes\n",
    "        where D^+ is the Moore-Penrose pseudoinverse.\n",
    "        \n",
    "        Args:\n",
    "            spikes (ndarray): Binary spike vector, shape (n_neurons,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat (ndarray): Decoded continuous estimate, shape (state_dim,).\n",
    "        \"\"\"\n",
    "        D_pinv = np.linalg.pinv(self.D)\n",
    "        x_hat = D_pinv @ spikes\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter module to perform optimal estimation (with delayed feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterSCN:\n",
    "    def __init__(self, A_init, B_init, C_init, L_init, delay):\n",
    "        \"\"\"\n",
    "        Initialize the Kalman filter with delay.\n",
    "        \n",
    "        Args:\n",
    "            A_init (ndarray): Initial system matrix A, shape (n, n).\n",
    "            B_init (ndarray): Initial control matrix B, shape (n, p).\n",
    "            C_init (ndarray): Initial observation matrix C, shape (m, n).\n",
    "            L_init (ndarray): Initial Kalman gain matrix L, shape (n, m).\n",
    "            delay (int): Sensory feedback delay τ (in timesteps).\n",
    "        \"\"\"\n",
    "        self.A = A_init\n",
    "        self.B = B_init\n",
    "        self.C = C_init\n",
    "        self.L = L_init\n",
    "        self.delay = delay\n",
    "        \n",
    "        # Should we maintain a buffer for state estimates to handle delays?\n",
    "        # For simplicity, I'll assume the caller provides the delayed state estimate.\n",
    "    \n",
    "    def predict_state(self, x_hat, u):\n",
    "        \"\"\"\n",
    "        Kalman prediction step.\n",
    "        \n",
    "        Predict the next state estimate based on the current estimate and control:\n",
    "            x_hat_pred = A x_hat + B u\n",
    "        \n",
    "        Args:\n",
    "            x_hat (ndarray): Current state estimate, shape (n,).\n",
    "            u (ndarray): Control input at time t, shape (p,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_pred (ndarray): Predicted next state, shape (n,).\n",
    "        \"\"\"\n",
    "        x_hat_pred = self.A @ x_hat + self.B @ u\n",
    "        return x_hat_pred\n",
    "\n",
    "    def update_state(self, x_hat_pred, y_delayed, x_hat_delayed):\n",
    "        \"\"\"\n",
    "        Kalman update step, incorporating delayed observation.\n",
    "        \n",
    "        This function implements:\n",
    "            x_hat_updated = x_hat_pred + L (y_{t+1-delay} - C x_hat_delayed)\n",
    "        \n",
    "        Args:\n",
    "            x_hat_pred (ndarray): Predicted state estimate at time t+1, shape (n,).\n",
    "            y_delayed (ndarray): Observation at time (t+1 - delay), shape (m,).\n",
    "            x_hat_delayed (ndarray): State estimate at time (t+1 - delay), shape (n,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_updated (ndarray): Updated state estimate, shape (n,).\n",
    "        \"\"\"\n",
    "        innovation = y_delayed - self.C @ x_hat_delayed  # prediction error (innovation)\n",
    "        x_hat_updated = x_hat_pred + self.L @ innovation\n",
    "        return x_hat_updated\n",
    "\n",
    "    def adapt_kalman_gain(self, error_current, error_delayed, learning_rate):\n",
    "        \"\"\"\n",
    "        Adapt the Kalman gain L using a local plasticity rule.\n",
    "        \n",
    "        Based on the Bio-OFC rule:\n",
    "            ΔL ∝ L (error_current) (error_delayed)^T\n",
    "        \n",
    "        where error_current = y_t - C x_hat_t and error_delayed = y_{t-delay} - C x_hat_{t-delay}.\n",
    "        \n",
    "        Args:\n",
    "            error_current (ndarray): Current prediction error, shape (m,).\n",
    "            error_delayed (ndarray): Delayed prediction error, shape (m,).\n",
    "            learning_rate (float): Step size for the adaptation.\n",
    "            \n",
    "        Updates self.L in place.\n",
    "        \"\"\"\n",
    "        # Outer product of errors (we assume L multiplies from left).\n",
    "        # TODO: Dimensional check before multiplication?\n",
    "        delta_L = learning_rate * self.L * np.outer(error_current, error_delayed)\n",
    "        self.L += delta_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal control using a policy-gradient-based learning rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientControllerSCN:\n",
    "    def __init__(self, K_init, noise_std, learning_rate, momentum=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the policy gradient based controller.\n",
    "        \n",
    "        Args:\n",
    "            K_init (ndarray): Initial control gain matrix K with shape (p, n),\n",
    "                              where p = control dimension, n = state dimension.\n",
    "            noise_std (float): Standard deviation of the exploration noise.\n",
    "            learning_rate (float): Learning rate for policy gradient updates.\n",
    "            momentum (float): Momentum parameter (default is 0), for smoothing updates.\n",
    "        \"\"\"\n",
    "        self.K = K_init.copy()\n",
    "        self.noise_std = noise_std\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        # Initialize the momentum accumulator for gradients with zeros\n",
    "        self.G = np.zeros_like(K_init)\n",
    "\n",
    "    def compute_action(self, state_estimate):\n",
    "        \"\"\"\n",
    "        Compute the control action with exploration noise.\n",
    "        \n",
    "        The deterministic part is given by the linear control law:\n",
    "            u_det = -K x_hat_t\n",
    "        and then we add Gaussian noise to encourage exploration:\n",
    "            u_t = u_det + noise, where noise ∼ N(0, noise_std)\n",
    "            \n",
    "        Args:\n",
    "            state_estimate (ndarray): Current state estimate x̂_t with shape (n,).\n",
    "            \n",
    "        Returns:\n",
    "            u (ndarray): Control action, shape (p,).\n",
    "            noise (ndarray): The exploration noise added to the control, shape (p,).\n",
    "        \"\"\"\n",
    "        # Compute deterministic control action.\n",
    "        u_det = -self.K @ state_estimate\n",
    "        # Generate exploration noise.\n",
    "        noise = np.random.normal(0, self.noise_std, size=u_det.shape)\n",
    "        # Compute final control action.\n",
    "        u = u_det + noise\n",
    "        return u, noise\n",
    "\n",
    "    def compute_eligibility_trace(self, prev_trace, state_estimate, noise):\n",
    "        \"\"\"\n",
    "        Compute the eligibility trace update based on the policy gradient formulation.\n",
    "        \n",
    "        The eligibility trace is accumulated as:\n",
    "            Z_t = Z_{t-1} + noise * (state_estimate)^T\n",
    "            \n",
    "        Args:\n",
    "            prev_trace (ndarray): Previous eligibility trace Z_{t-1} with shape (p, n).\n",
    "            state_estimate (ndarray): Current state estimate x̂_t with shape (n,).\n",
    "            noise (ndarray): The exploration noise added to control, shape (p,).\n",
    "            \n",
    "        Returns:\n",
    "            trace (ndarray): Updated eligibility trace Z_t with shape (p, n).\n",
    "        \"\"\"\n",
    "        # The outer product noise (p,) and state_estimate (n,) gives a (p, n) matrix.\n",
    "        delta_trace = np.outer(noise, state_estimate)\n",
    "        trace = prev_trace + delta_trace\n",
    "        return trace\n",
    "\n",
    "    def update_policy(self, eligibility_trace, cost):\n",
    "        \"\"\"\n",
    "        Update the control gain matrix K using a policy gradient update.\n",
    "        \n",
    "        The update rule is:\n",
    "            ∆K ∝ -cost * eligibility_trace\n",
    "        With momentum incorporated, we update as:\n",
    "            G_t = momentum * G_{t-1} + cost * eligibility_trace\n",
    "            K_new = K_old - learning_rate * G_t\n",
    "        \n",
    "        Args:\n",
    "            eligibility_trace (ndarray): Current eligibility trace Z_t with shape (p, n).\n",
    "            cost (float): The cost incurred at the current time step.\n",
    "            \n",
    "        This method updates self.K in place.\n",
    "        \"\"\"\n",
    "        # Incorporate momentum in the gradient update.\n",
    "        self.G = self.momentum * self.G + cost * eligibility_trace\n",
    "        # Update the control gain matrix K in the negative gradient direction.\n",
    "        self.K = self.K - self.learning_rate * self.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Bio-OFC module combining Kalman filtering and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioOFC:\n",
    "    def __init__(self, kalman_filter, controller, system_matrices):\n",
    "        \"\"\"\n",
    "        Initialize the Bio-OFC module.\n",
    "        \n",
    "        Args:\n",
    "            kalman_filter (KalmanFilterSCN): An instance of KalmanFilterSCN.\n",
    "            controller (PolicyGradientControllerSCN): An instance of PolicyGradientControllerSCN.\n",
    "            system_matrices (dict): Dictionary containing system matrices:\n",
    "                - 'A': System matrix A.\n",
    "                - 'B': Input matrix B.\n",
    "                - 'C': Observation matrix C.\n",
    "        \"\"\"\n",
    "        self.kf = kalman_filter\n",
    "        self.controller = controller\n",
    "        self.A = system_matrices['A']\n",
    "        self.B = system_matrices['B']\n",
    "        self.C = system_matrices['C']\n",
    "    \n",
    "    def step(self, x_hat, u, observation, delayed_observation, x_hat_delayed, params):\n",
    "        \"\"\"\n",
    "        Performs a single step of optimal feedback control.\n",
    "        \n",
    "        The step consists of:\n",
    "         1. Predict: x_hat_pred = A x_hat + B u.\n",
    "         2. Update: x_hat_updated = x_hat_pred + L (y_delayed - C x_hat_delayed).\n",
    "         3. Compute control action: u_new = -K x_hat_updated + exploration_noise.\n",
    "         4. (Optionally) Update the internal weights using the error signals.\n",
    "         \n",
    "        Args:\n",
    "            x_hat (ndarray): Current state estimate, shape (n,).\n",
    "            u (ndarray): Current control input, shape (p,).\n",
    "            observation (ndarray): Current (possibly delayed) observation y_t.\n",
    "            delayed_observation (ndarray): Observation from time t+1-τ.\n",
    "            x_hat_delayed (ndarray): State estimate from time t+1-τ.\n",
    "            params (dict): Additional parameters, which may include:\n",
    "                - 'learning_rate_kf': learning rate for Kalman gain update.\n",
    "                - 'learning_rate_controller': learning rate for controller update.\n",
    "                - 'cost': current cost incurred.\n",
    "                - 'prev_eligibility': previous eligibility trace for the controller.\n",
    "                - 'error_delayed': error from delayed measurement (if computed externally).\n",
    "                \n",
    "        Returns:\n",
    "            x_hat_updated (ndarray): Updated state estimate.\n",
    "            u_new (ndarray): New control action.\n",
    "            new_eligibility (ndarray): Updated controller eligibility trace.\n",
    "        \"\"\"\n",
    "        # 1. Prediction step using Kalman filter:\n",
    "        x_hat_pred = self.kf.predict_state(x_hat, u)\n",
    "        \n",
    "        # 2. Update state estimate with delayed observation:\n",
    "        x_hat_updated = self.kf.update_state(x_hat_pred, delayed_observation, x_hat_delayed)\n",
    "        \n",
    "        # (Optional) Compute innovation error for possible learning of Kalman gain:\n",
    "        error = delayed_observation - self.C @ x_hat_delayed\n",
    "        \n",
    "        # For updating Kalman gain L (if using a delayed error term)\n",
    "        if 'error_delayed' in params:\n",
    "            self.kf.adapt_kalman_gain(error, params['error_delayed'], params.get('learning_rate_kf', 0.001))\n",
    "        \n",
    "        # 3. Use the updated state estimate to compute control action.\n",
    "        u_new, noise = self.controller.compute_action(x_hat_updated)\n",
    "        \n",
    "        # 4. Update controller eligibility trace.\n",
    "        prev_trace = params.get('prev_eligibility', np.zeros_like(self.controller.K))\n",
    "        new_trace = self.controller.compute_eligibility_trace(prev_trace, x_hat_updated, noise)\n",
    "        \n",
    "        # 5. Update the controller (policy) using the current cost signal.\n",
    "        cost = params.get('cost', 0.0)\n",
    "        self.controller.update_policy(new_trace, cost)\n",
    "        \n",
    "        return x_hat_updated, u_new, new_trace\n",
    "\n",
    "    def adapt_system_matrices(self, error, x_hat_delayed, u_delayed, x_hat_next_delayed, learning_rates):\n",
    "        \"\"\"\n",
    "        Adapt the system matrices A, B, and C using local plasticity rules.\n",
    "        \n",
    "        The rules are:\n",
    "            ΔA ∝ L * error * (x_hat_delayed)^T\n",
    "            ΔB ∝ L * error * (u_delayed)^T\n",
    "            ΔC ∝ error * (x_hat_next_delayed)^T\n",
    "        \n",
    "        Args:\n",
    "            error (ndarray): Prediction error at time t, computed as y_t - C x_hat_t.\n",
    "            x_hat_delayed (ndarray): Delayed state estimate x_hat_{t-τ}, shape (n,).\n",
    "            u_delayed (ndarray): Delayed control input u_{t-τ}, shape (p,).\n",
    "            x_hat_next_delayed (ndarray): Delayed state estimate at time t+1, shape (n,).\n",
    "            learning_rates (dict): Dictionary of learning rates with keys:\n",
    "                - 'A': learning rate for A.\n",
    "                - 'B': learning rate for B.\n",
    "                - 'C': learning rate for C.\n",
    "        \"\"\"\n",
    "        lr_A = learning_rates.get('A', 0.001)\n",
    "        lr_B = learning_rates.get('B', 0.001)\n",
    "        lr_C = learning_rates.get('C', 0.001)\n",
    "        \n",
    "        # Adapt A: ΔA ∝ L * error * (x_hat_delayed)^T\n",
    "        delta_A = lr_A * self.kf.L @ np.outer(error, x_hat_delayed)\n",
    "        self.A += delta_A\n",
    "        self.kf.A = self.A  # update the Kalman filter's internal A\n",
    "        \n",
    "        # Adapt B: ΔB ∝ L * error * (u_delayed)^T\n",
    "        delta_B = lr_B * self.kf.L @ np.outer(error, u_delayed)\n",
    "        self.B += delta_B\n",
    "        self.kf.B = self.B  # update the Kalman filter's internal B\n",
    "        \n",
    "        # Adapt C: ΔC ∝ error * (x_hat_next_delayed)^T\n",
    "        delta_C = lr_C * np.outer(error, x_hat_next_delayed)\n",
    "        self.C += delta_C\n",
    "        self.kf.C = self.C  # update the Kalman filter's internal C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main execution loop performing simulations, estimation, control, and learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(metrics):\n",
    "    \"\"\"\n",
    "    Plot performance metrics over episodes.\n",
    "    \n",
    "    metrics is a dictionary with keys:\n",
    "        'episode_costs': average cost per episode.\n",
    "        'episode_mse': mean squared error between the true state and the state estimate.\n",
    "    \"\"\"\n",
    "    episodes = np.arange(len(metrics['episode_costs']))\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(episodes, metrics['episode_costs'], marker='o', label=\"Avg Cost\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.title(\"Cost per Episode\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(episodes, metrics['episode_mse'], marker='o', label=\"Avg MSE\", color='orange')\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Mean Squared Error per Episode\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spike_activity(spikes):\n",
    "    \"\"\"\n",
    "    Create a raster plot of spiking activity.\n",
    "    \n",
    "    spikes: a 2D array (timesteps x neurons). Each row is a binary vector of spikes.\n",
    "    \"\"\"\n",
    "    spikes = np.array(spikes)\n",
    "    num_timesteps, num_neurons = spikes.shape\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for t in range(num_timesteps):\n",
    "        neuron_indices = np.where(spikes[t] > 0)[0]\n",
    "        # Plot each spike as a vertical line at time t\n",
    "        plt.vlines(t, neuron_indices - 0.5, neuron_indices + 0.5, colors='black')\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.ylabel(\"Neuron index\")\n",
    "    plt.title(\"Spike Raster Plot\")\n",
    "    plt.show()\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"\n",
    "    Save simulation results to a file using np.savez.\n",
    "    \n",
    "    results: a dictionary of arrays.\n",
    "    filename: the filename to save (e.g., 'results.npz').\n",
    "    \"\"\"\n",
    "    np.savez(filename, **results)\n",
    "    print(\"Results saved to\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "    # Simulation parameters\n",
    "    num_episodes = 50\n",
    "    timesteps_per_episode = 100\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize the SMD simulator\n",
    "    # ----------------------------\n",
    "    mass = 1.0\n",
    "    spring_const = 5.0\n",
    "    damping_coeff = 0.5\n",
    "    dt = 0.01\n",
    "    process_noise_cov = np.diag([0.001, 0.001])\n",
    "    sim = SpringMassDamperSimulator(mass, spring_const, damping_coeff, dt, process_noise_cov)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize the SCN module (for future use/recording spikes)\n",
    "    # ----------------------------\n",
    "    lambda_decay = 0.1\n",
    "    dims = 10  # number of neurons for the SCN (for spike encoding/decoding)\n",
    "    scn = SpikeCodingNetwork(lambda_decay, dims, threshold=1.0)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize system matrices for the Kalman filter and Bio-OFC.\n",
    "    # (Assume state dimension n=2, control dimension p=1, observation dimension m=1)\n",
    "    # ----------------------------\n",
    "    A_init = np.array([[1.0, dt],\n",
    "                       [0.0, 1.0]])\n",
    "    B_init = np.array([[0.0],\n",
    "                       [dt / mass]])\n",
    "    C_init = np.array([[1.0, 0.0]])\n",
    "    L_init = np.array([[0.1],\n",
    "                       [0.1]])\n",
    "    delay = 1  # sensory feedback delay (in timesteps)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize the Kalman filter module.\n",
    "    # ----------------------------\n",
    "    kf = KalmanFilterSCN(A_init, B_init, C_init, L_init, delay)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize the policy-gradient controller.\n",
    "    # ----------------------------\n",
    "    # Control gain K: shape (p, n) for p=1, n=2.\n",
    "    K_init = np.random.randn(1, 2) * 0.1\n",
    "    noise_std = 0.05\n",
    "    controller_lr = 0.01\n",
    "    momentum = 0.9\n",
    "    controller = PolicyGradientControllerSCN(K_init, noise_std, controller_lr, momentum)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Create the Bio-OFC module combining the Kalman filter and controller.\n",
    "    # ----------------------------\n",
    "    system_matrices = {'A': A_init, 'B': B_init, 'C': C_init}\n",
    "    bio_ofc = BioOFC(kf, controller, system_matrices)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize metric recording containers\n",
    "    # ----------------------------\n",
    "    episode_costs = []\n",
    "    episode_mse = []\n",
    "    spike_record = []  # record spike activity (optional, from SCN)\n",
    "    \n",
    "    # Assume we want the target state to be zero.\n",
    "    target = np.array([0.0, 0.0])\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Initialize state and state estimate.\n",
    "    # ----------------------------\n",
    "    state = np.array([1.0, 0.0])\n",
    "    x_hat = state.copy()  # initial state estimate\n",
    "    # For delay=1, initialize delayed observation and state estimate.\n",
    "    delayed_observation = sim.observe(state)\n",
    "    x_hat_delayed = x_hat.copy()\n",
    "    \n",
    "    # Initialize eligibility trace for the controller.\n",
    "    eligibility_trace = np.zeros_like(controller.K)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Simulation loop over episodes\n",
    "    # ----------------------------\n",
    "    for ep in range(num_episodes):\n",
    "        total_cost = 0.0\n",
    "        mse_list = []\n",
    "        episode_spikes = []  # record spike encoding from SCN\n",
    "        # Reset state for the episode (could add variability)\n",
    "        state = np.array([1.0, 0.0])\n",
    "        x_hat = state.copy()\n",
    "        delayed_observation = sim.observe(state)\n",
    "        x_hat_delayed = x_hat.copy()\n",
    "        eligibility_trace = np.zeros_like(controller.K)\n",
    "        \n",
    "        for t in range(timesteps_per_episode):\n",
    "            # Compute instantaneous cost (e.g., squared error between state and target)\n",
    "            cost = np.sum((state - target)**2)\n",
    "            total_cost += cost\n",
    "            \n",
    "            # Prepare parameters for Bio-OFC step.\n",
    "            params = {\n",
    "                'learning_rate_kf': 0.001,\n",
    "                'cost': cost,\n",
    "                'prev_eligibility': eligibility_trace,\n",
    "                # For simplicity, provide a placeholder for delayed error.\n",
    "                'error_delayed': np.array([0.0])\n",
    "            }\n",
    "            \n",
    "            # Bio-OFC step: Prediction, update, control computation, and policy update.\n",
    "            # The function takes:\n",
    "            #   x_hat (current state estimate),\n",
    "            #   u (previous control, here we pass a dummy control of zero initially),\n",
    "            #   observation (current observation),\n",
    "            #   delayed_observation (observation from time t+1-delay),\n",
    "            #   x_hat_delayed (state estimate from time t+1-delay),\n",
    "            #   params (dictionary).\n",
    "            x_hat_updated, u_new, new_trace = bio_ofc.step(\n",
    "                x_hat,\n",
    "                np.array([0.0]),  # For the first step, pass dummy control input.\n",
    "                sim.observe(state),\n",
    "                delayed_observation,\n",
    "                x_hat_delayed,\n",
    "                params\n",
    "            )\n",
    "            \n",
    "            # Update eligibility trace for the controller.\n",
    "            eligibility_trace = new_trace\n",
    "            \n",
    "            # Apply the computed control action to the simulator.\n",
    "            # Here, u_new is an array of shape (1,), use its first element.\n",
    "            next_state, observation = sim.step(state, u_new[0])\n",
    "            \n",
    "            # Compute mean squared error between true state and state estimate.\n",
    "            mse = np.mean((state - x_hat)**2)\n",
    "            mse_list.append(mse)\n",
    "            \n",
    "            # Optionally, record spike activity via the SCN encode() function using x_hat.\n",
    "            spikes = scn.encode(x_hat)\n",
    "            episode_spikes.append(spikes)\n",
    "            \n",
    "            # Update state and the state estimate for the next timestep.\n",
    "            state = next_state\n",
    "            x_hat = x_hat_updated.copy()\n",
    "            \n",
    "            # For handling delay, update delayed observation and x_hat_delayed.\n",
    "            delayed_observation = observation\n",
    "            x_hat_delayed = x_hat.copy()\n",
    "        \n",
    "        # End of episode: record average cost and mse.\n",
    "        avg_cost = total_cost / timesteps_per_episode\n",
    "        avg_mse = np.mean(mse_list)\n",
    "        episode_costs.append(avg_cost)\n",
    "        episode_mse.append(avg_mse)\n",
    "        spike_record.append(np.array(episode_spikes))\n",
    "        print(f\"Episode {ep+1}/{num_episodes}: Avg Cost = {avg_cost:.4f}, Avg MSE = {avg_mse:.4f}\")\n",
    "    \n",
    "    # Compile results into a dictionary.\n",
    "    results = {\n",
    "        'episode_costs': np.array(episode_costs),\n",
    "        'episode_mse': np.array(episode_mse),\n",
    "        'spike_record': spike_record\n",
    "    }\n",
    "    \n",
    "    # Plot performance metrics.\n",
    "    plot_performance(results)\n",
    "    # Plot spike activity for the first episode.\n",
    "    if spike_record:\n",
    "        plot_spike_activity(spike_record[0])\n",
    "    # Save the results to a file.\n",
    "    save_results(results, \"bio_ofc_results.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 136\u001b[39m, in \u001b[36mrun_simulation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    133\u001b[39m mse_list.append(mse)\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Optionally, record spike activity via the SCN encode() function using x_hat.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m spikes = \u001b[43mscn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_hat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m episode_spikes.append(spikes)\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# Update state and the state estimate for the next timestep.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mSpikeCodingNetwork.encode\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     27\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    Spike encoding of a continuous variable x.\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \u001b[33;03m        spikes (ndarray): Encoded binary spike vector, shape (dims,).\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     potentials = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mD\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[32m     41\u001b[39m     spikes = (potentials >= \u001b[38;5;28mself\u001b[39m.threshold).astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m spikes\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 2 is different from 10)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_simulation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

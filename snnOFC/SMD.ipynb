{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simulator for a discrete-time linear Spring-Mass-Damper (SMD) environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SpringMassDamperSimulator:\n",
    "    def __init__(self, mass, spring_const, damping_coeff, dt, noise_cov):\n",
    "        \"\"\"\n",
    "        Initialize the SMD simulator.\n",
    "        \n",
    "        Args:\n",
    "            mass (float): mass m.\n",
    "            spring_const (float): spring constant k.\n",
    "            damping_coeff (float): damping coefficient b.\n",
    "            dt (float): time-step size.\n",
    "            noise_cov (ndarray): Process noise covariance matrix, shape (2, 2).\n",
    "        \"\"\"\n",
    "        self.m = mass\n",
    "        self.k = spring_const\n",
    "        self.b = damping_coeff\n",
    "        self.dt = dt\n",
    "        self.noise_cov = noise_cov\n",
    "        # Define the observation matrix C.\n",
    "        # For example, we may assume we only observe position.\n",
    "        self.C = np.array([[1.0, 0.0]])  # shape (1, 2)\n",
    "\n",
    "    def step(self, state, control_input):\n",
    "        \"\"\"\n",
    "        Update the system state using Euler integration.\n",
    "        \n",
    "        Discrete-time dynamics:\n",
    "            x₁(t+1) = x₁(t) + dt * x₂(t)\n",
    "            x₂(t+1) = x₂(t) + dt * (1/m * (control_input - b*x₂(t) - k*x₁(t)))\n",
    "            \n",
    "        Also adds process noise v ~ N(0, noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): Current state [position; velocity], shape (2,).\n",
    "            control_input (float): Control input applied at time t.\n",
    "        \n",
    "        Returns:\n",
    "            next_state (ndarray): Updated state, shape (2,).\n",
    "            observation (ndarray): Noisy observation, shape matches self.C * state.\n",
    "        \"\"\"\n",
    "        pos, vel = state  # Unpack position and velocity\n",
    "        \n",
    "        # Compute derivatives using SMD dynamics.\n",
    "        dpos_dt = vel\n",
    "        dvel_dt = (control_input - self.b * vel - self.k * pos) / self.m\n",
    "        \n",
    "        # Euler integration to update state.\n",
    "        state_dot = np.array([dpos_dt, dvel_dt])\n",
    "        next_state = state + self.dt * state_dot\n",
    "        \n",
    "        # Add process noise v_t ~ N(0, noise_cov)\n",
    "        process_noise = np.random.multivariate_normal(mean=np.zeros(2), cov=self.noise_cov)\n",
    "        next_state = next_state + process_noise\n",
    "        \n",
    "        # Get noisy observation using the 'observe' method.\n",
    "        # We can set our own observation noise covariance in the observe method.\n",
    "        observation = self.observe(next_state)\n",
    "        \n",
    "        return next_state, observation\n",
    "\n",
    "    def observe(self, state, obs_noise_cov=np.array([[0.1]])):\n",
    "        \"\"\"\n",
    "        Generate a noisy observation of the current state.\n",
    "        \n",
    "        Observation equation:\n",
    "            y_t = C * x_t + w_t,\n",
    "        where w_t ~ N(0, obs_noise_cov).\n",
    "        \n",
    "        Args:\n",
    "            state (ndarray): State vector, shape (2,).\n",
    "            obs_noise_cov (ndarray): Observation noise covariance, shape (1, 1) \n",
    "                                     if observation is one-dimensional.\n",
    "        \n",
    "        Returns:\n",
    "            observation (ndarray): Noisy observation, shape (1,).\n",
    "        \"\"\"\n",
    "        # Linear observation: we assume we only observe the position.\n",
    "        observation = self.C @ state  # This is a (1,) vector.\n",
    "        \n",
    "        # Add observation noise.\n",
    "        w = np.random.multivariate_normal(mean=np.zeros(self.C.shape[0]), cov=obs_noise_cov)\n",
    "        observation = observation + w\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Coding Network implementation (LIF neurons, spike encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikeCodingNetwork:\n",
    "    def __init__(self, lambda_decay, dims, threshold=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Spike Coding Network.\n",
    "        \n",
    "        Args:\n",
    "            lambda_decay (float): Voltage decay rate λ.\n",
    "            dims (int): Number of neurons (and dimension of state/input/spikes).\n",
    "            threshold (float): Voltage threshold for spiking.\n",
    "        \"\"\"\n",
    "        self.lambda_decay = lambda_decay\n",
    "        self.dims = dims\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # We initialize the slow and fast recurrent weight matrices.\n",
    "        # In SCNs, fast recurrent connections are typically set as Ω_f = -D^T D.\n",
    "        # But here I initialize them to zero and hopefully later they can be set/learned?\n",
    "        # I should check this later...\n",
    "        self.Omega_s = np.zeros((dims, dims))   # slow recurrent weights\n",
    "        self.Omega_f = np.zeros((dims, dims))   # fast recurrent weights\n",
    "        \n",
    "        # Decoding matrix D maps between spike space and continuous space.\n",
    "        # For simplicity, we assume D is square and initialize it randomly.\n",
    "        self.D = np.random.randn(dims, dims)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Spike encoding of a continuous variable x.\n",
    "        \n",
    "        For simplicity, we assume a linear encoding:\n",
    "            potentials = D^T x\n",
    "        and then threshold the potentials to generate binary spikes.\n",
    "        \n",
    "        Args:\n",
    "            x (ndarray): Continuous input vector, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Encoded binary spike vector, shape (dims,).\n",
    "        \"\"\"\n",
    "        potentials = self.D.T @ x\n",
    "        spikes = (potentials >= self.threshold).astype(float)\n",
    "        return spikes\n",
    "\n",
    "    def update_voltages(self, voltages, inputs, r, s, noise_std=0.01):\n",
    "        \"\"\"\n",
    "        Update the membrane voltages using the following dynamics:\n",
    "        \n",
    "            v_dot = -λ v + Ω_s r + Ω_f s + Input + noise\n",
    "            \n",
    "        and then perform Euler integration:\n",
    "        \n",
    "            v_{t+1} = v_t + v_dot   (assuming dt=1)\n",
    "        \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (dims,).\n",
    "            inputs (ndarray): External input currents, shape (dims,).\n",
    "            r (ndarray): Filtered spike trains (e.g., low-pass filtered spikes), shape (dims,).\n",
    "            s (ndarray): Recent spikes, shape (dims,).\n",
    "            noise_std (float): Standard deviation for Gaussian noise.\n",
    "            \n",
    "        Returns:\n",
    "            new_voltages (ndarray): Updated membrane voltages, shape (dims,).\n",
    "        \"\"\"\n",
    "        noise = np.random.normal(0, noise_std, size=voltages.shape)\n",
    "        # Compute the derivative of the voltages.\n",
    "        v_dot = (-self.lambda_decay * voltages +\n",
    "                 self.Omega_s @ r +\n",
    "                 self.Omega_f @ s +\n",
    "                 inputs +\n",
    "                 noise)\n",
    "        # Euler integration with dt=1.\n",
    "        new_voltages = voltages + v_dot\n",
    "        return new_voltages\n",
    "\n",
    "    def generate_spikes(self, voltages):\n",
    "        \"\"\"\n",
    "        Generate spikes based on the current membrane voltages.\n",
    "        \n",
    "        If a neuron's voltage exceeds the threshold, it emits a spike and the voltage is reset.\n",
    "        \n",
    "        Args:\n",
    "            voltages (ndarray): Current membrane voltages, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            spikes (ndarray): Binary vector indicating spikes, shape (dims,).\n",
    "            updated_voltages (ndarray): Voltages after spike reset, shape (dims,).\n",
    "        \"\"\"\n",
    "        spikes = (voltages >= self.threshold).astype(float)\n",
    "        # Reset the voltages for neurons that have spiked.\n",
    "        updated_voltages = np.copy(voltages)\n",
    "        updated_voltages[spikes == 1] = 0.0\n",
    "        return spikes, updated_voltages\n",
    "\n",
    "    def decode(self, spikes):\n",
    "        \"\"\"\n",
    "        Decode spikes to recover the continuous variable estimate.\n",
    "        \n",
    "        Here we assume a linear decoding:\n",
    "            x_hat = D @ spikes\n",
    "        In a full implementation, one might low-pass filter the spikes (r) and then decode.\n",
    "        \n",
    "        Args:\n",
    "            spikes (ndarray): Binary spike vector, shape (dims,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat (ndarray): Decoded continuous estimate, shape (dims,).\n",
    "        \"\"\"\n",
    "        x_hat = self.D @ spikes\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter module to perform optimal estimation (with delayed feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterSCN:\n",
    "    def __init__(self, A_init, B_init, C_init, L_init, delay):\n",
    "        \"\"\"\n",
    "        Initialize the Kalman filter with delay.\n",
    "        \n",
    "        Args:\n",
    "            A_init (ndarray): Initial system matrix A, shape (n, n).\n",
    "            B_init (ndarray): Initial control matrix B, shape (n, p).\n",
    "            C_init (ndarray): Initial observation matrix C, shape (m, n).\n",
    "            L_init (ndarray): Initial Kalman gain matrix L, shape (n, m).\n",
    "            delay (int): Sensory feedback delay τ (in timesteps).\n",
    "        \"\"\"\n",
    "        self.A = A_init\n",
    "        self.B = B_init\n",
    "        self.C = C_init\n",
    "        self.L = L_init\n",
    "        self.delay = delay\n",
    "        \n",
    "        # Should we maintain a buffer for state estimates to handle delays?\n",
    "        # For simplicity, I'll assume the caller provides the delayed state estimate.\n",
    "    \n",
    "    def predict_state(self, x_hat, u):\n",
    "        \"\"\"\n",
    "        Kalman prediction step.\n",
    "        \n",
    "        Predict the next state estimate based on the current estimate and control:\n",
    "            x_hat_pred = A x_hat + B u\n",
    "        \n",
    "        Args:\n",
    "            x_hat (ndarray): Current state estimate, shape (n,).\n",
    "            u (ndarray): Control input at time t, shape (p,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_pred (ndarray): Predicted next state, shape (n,).\n",
    "        \"\"\"\n",
    "        x_hat_pred = self.A @ x_hat + self.B @ u\n",
    "        return x_hat_pred\n",
    "\n",
    "    def update_state(self, x_hat_pred, y_delayed, x_hat_delayed):\n",
    "        \"\"\"\n",
    "        Kalman update step, incorporating delayed observation.\n",
    "        \n",
    "        This function implements:\n",
    "            x_hat_updated = x_hat_pred + L (y_{t+1-delay} - C x_hat_delayed)\n",
    "        \n",
    "        Args:\n",
    "            x_hat_pred (ndarray): Predicted state estimate at time t+1, shape (n,).\n",
    "            y_delayed (ndarray): Observation at time (t+1 - delay), shape (m,).\n",
    "            x_hat_delayed (ndarray): State estimate at time (t+1 - delay), shape (n,).\n",
    "            \n",
    "        Returns:\n",
    "            x_hat_updated (ndarray): Updated state estimate, shape (n,).\n",
    "        \"\"\"\n",
    "        innovation = y_delayed - self.C @ x_hat_delayed  # prediction error (innovation)\n",
    "        x_hat_updated = x_hat_pred + self.L @ innovation\n",
    "        return x_hat_updated\n",
    "\n",
    "    def adapt_kalman_gain(self, error_current, error_delayed, learning_rate):\n",
    "        \"\"\"\n",
    "        Adapt the Kalman gain L using a local plasticity rule.\n",
    "        \n",
    "        Based on the Bio-OFC rule:\n",
    "            ΔL ∝ L (error_current) (error_delayed)^T\n",
    "        \n",
    "        where error_current = y_t - C x_hat_t and error_delayed = y_{t-delay} - C x_hat_{t-delay}.\n",
    "        \n",
    "        Args:\n",
    "            error_current (ndarray): Current prediction error, shape (m,).\n",
    "            error_delayed (ndarray): Delayed prediction error, shape (m,).\n",
    "            learning_rate (float): Step size for the adaptation.\n",
    "            \n",
    "        Updates self.L in place.\n",
    "        \"\"\"\n",
    "        # Outer product of errors (we assume L multiplies from left).\n",
    "        # TODO: Dimensional check before multiplication?\n",
    "        delta_L = learning_rate * self.L * np.outer(error_current, error_delayed)\n",
    "        self.L += delta_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
